{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23513de5",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:04.418658Z",
     "iopub.status.busy": "2025-12-22T19:24:04.417976Z",
     "iopub.status.idle": "2025-12-22T19:24:08.698315Z",
     "shell.execute_reply": "2025-12-22T19:24:08.697559Z"
    },
    "papermill": {
     "duration": 4.287507,
     "end_time": "2025-12-22T19:24:08.700112",
     "exception": false,
     "start_time": "2025-12-22T19:24:04.412605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting striprtf\r\n",
      "  Downloading striprtf-0.0.29-py3-none-any.whl.metadata (2.3 kB)\r\n",
      "Downloading striprtf-0.0.29-py3-none-any.whl (7.9 kB)\r\n",
      "Installing collected packages: striprtf\r\n",
      "Successfully installed striprtf-0.0.29\r\n"
     ]
    }
   ],
   "source": [
    "!pip install striprtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f85f0da5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:08.708235Z",
     "iopub.status.busy": "2025-12-22T19:24:08.707976Z",
     "iopub.status.idle": "2025-12-22T19:24:11.462538Z",
     "shell.execute_reply": "2025-12-22T19:24:11.461658Z"
    },
    "papermill": {
     "duration": 2.760487,
     "end_time": "2025-12-22T19:24:11.464230",
     "exception": false,
     "start_time": "2025-12-22T19:24:08.703743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import striprtf\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import re, string\n",
    "from collections import Counter\n",
    "\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e14e5f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:11.472467Z",
     "iopub.status.busy": "2025-12-22T19:24:11.471636Z",
     "iopub.status.idle": "2025-12-22T19:24:15.048314Z",
     "shell.execute_reply": "2025-12-22T19:24:15.047489Z"
    },
    "papermill": {
     "duration": 3.582421,
     "end_time": "2025-12-22T19:24:15.050020",
     "exception": false,
     "start_time": "2025-12-22T19:24:11.467599",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09b6cf0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:15.057927Z",
     "iopub.status.busy": "2025-12-22T19:24:15.057590Z",
     "iopub.status.idle": "2025-12-22T19:24:15.062211Z",
     "shell.execute_reply": "2025-12-22T19:24:15.061724Z"
    },
    "papermill": {
     "duration": 0.010068,
     "end_time": "2025-12-22T19:24:15.063622",
     "exception": false,
     "start_time": "2025-12-22T19:24:15.053554",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_convert(file_path):\n",
    "    \"\"\"Loads an RTF file, converts it to plain text\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            rtf_content = f.read()\n",
    "\n",
    "        # Convert RTF to plain text\n",
    "        plain_text = rtf_to_text(rtf_content)\n",
    "        \n",
    "        return plain_text\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File not found at {file_path}. Returning empty string.\")\n",
    "        return \"\"\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {file_path}: {e}\")\n",
    "        return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54a9145f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:15.071072Z",
     "iopub.status.busy": "2025-12-22T19:24:15.070622Z",
     "iopub.status.idle": "2025-12-22T19:24:16.324730Z",
     "shell.execute_reply": "2025-12-22T19:24:16.323888Z"
    },
    "papermill": {
     "duration": 1.260088,
     "end_time": "2025-12-22T19:24:16.326828",
     "exception": false,
     "start_time": "2025-12-22T19:24:15.066740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_1 = '/kaggle/input/dune-frank-herbert/dune/dune.rtf'\n",
    "file_path_2 = '/kaggle/input/dune-frank-herbert/dune/dune-messiah.rtfd/TXT.rtf'\n",
    "\n",
    "text_dune = load_convert(file_path_1)\n",
    "text_dune_messiah = load_convert(file_path_2)\n",
    "\n",
    "separator = \"\\n\\n--- END OF DUNE / START OF DUNE MESSIAH ---\\n\\n\"\n",
    "combined_text = text_dune + separator + text_dune_messiah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c99824d8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:16.334730Z",
     "iopub.status.busy": "2025-12-22T19:24:16.334477Z",
     "iopub.status.idle": "2025-12-22T19:24:16.339594Z",
     "shell.execute_reply": "2025-12-22T19:24:16.338974Z"
    },
    "papermill": {
     "duration": 0.010529,
     "end_time": "2025-12-22T19:24:16.340890",
     "exception": false,
     "start_time": "2025-12-22T19:24:16.330361",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Книга перша\\u2028Dюна\\n1\\nПочаток — то мить, коли варто якнайкраще подбати про істинну рівновагу речей. Кожна сестра Бене Ґессерит[2] знає про це. Тож, приступаючи до вивчення життя Муад’Діба, зважте спершу на те, у які часи він з’явився, бо ж народився владар у рік п’ятдесят сьомий правління Падишаха-Імператора Шаддама IV. Й особливо уважно придивіться, де саме він з’явився: на планеті Арракіс. Хай не вводить вас в оману той факт, що народився він і прожив перші п’ятнадцять років свого життя на Калада'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4d73f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:16.348347Z",
     "iopub.status.busy": "2025-12-22T19:24:16.348081Z",
     "iopub.status.idle": "2025-12-22T19:24:16.515168Z",
     "shell.execute_reply": "2025-12-22T19:24:16.514390Z"
    },
    "papermill": {
     "duration": 0.173209,
     "end_time": "2025-12-22T19:24:16.517320",
     "exception": false,
     "start_time": "2025-12-22T19:24:16.344111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "книга перша дюна початок — то мить, коли варто якнайкраще подбати про істинну рівновагу речей. кожна сестра бене ґессерит знає про це. тож, приступаючи до вивчення життя муад’діба, зважте спершу на те, у які часи він з’явився, бо ж народився владар у рік п’ятдесят сьомий правління падишаха-імператора шаддама iv. й особливо уважно придивіться, де саме він з’явився: на планеті арракіс. хай не вводить вас в оману той факт, що народився він і прожив перші п’ятнадцять років свого життя на каладані. а\n"
     ]
    }
   ],
   "source": [
    "def clean_dune_text(text):\n",
    "\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove citation markers like [2], [10], etc.\n",
    "    text = re.sub(r'\\[\\d+\\]', '', text)\n",
    "\n",
    "    # Remove numbers (digits 0-9)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Fix specific OCR/Typo: Latin 'D' to Cyrillic 'Д' in 'Dюна'\n",
    "    text = text.replace('dюна', 'дюна')\n",
    "\n",
    "    # Remove punctuation\n",
    "    #text = re.sub(r'[^\\w\\s]', '', text)\n",
    "\n",
    "    # Normalize whitespace:\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Strip leading/trailing whitespace\n",
    "    return text.strip()\n",
    "\n",
    "cleaned_text = clean_dune_text(combined_text)\n",
    "print(cleaned_text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be8c2b",
   "metadata": {
    "papermill": {
     "duration": 0.005318,
     "end_time": "2025-12-22T19:24:16.528462",
     "exception": false,
     "start_time": "2025-12-22T19:24:16.523144",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Tokenize the text into words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d6f1a96c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:16.537317Z",
     "iopub.status.busy": "2025-12-22T19:24:16.536674Z",
     "iopub.status.idle": "2025-12-22T19:24:17.423358Z",
     "shell.execute_reply": "2025-12-22T19:24:17.422532Z"
    },
    "papermill": {
     "duration": 0.892697,
     "end_time": "2025-12-22T19:24:17.424913",
     "exception": false,
     "start_time": "2025-12-22T19:24:16.532216",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['книга', 'перша', 'дюна', 'початок', '—', 'то', 'мить,', 'коли', 'варто', 'якнайкраще', 'подбати', 'про', 'істинну', 'рівновагу', 'речей.', 'кожна', 'сестра', 'бене', 'ґессерит', 'знає', 'це.', 'тож,', 'приступаючи', 'до', 'вивчення', 'життя', 'муад’діба,', 'зважте', 'спершу', 'на', 'те,', 'у', 'які', 'часи', 'він', 'з’явився,', 'бо', 'ж', 'народився', 'владар', 'рік', 'п’ятдесят', 'сьомий', 'правління', 'падишаха-імператора', 'шаддама', 'iv.', 'й', 'особливо', 'уважно']\n",
      "{'книга': 0, 'перша': 1, 'дюна': 2, 'початок': 3, '—': 4, 'то': 5, 'мить,': 6, 'коли': 7, 'варто': 8, 'якнайкраще': 9, 'подбати': 10, 'про': 11, 'істинну': 12, 'рівновагу': 13, 'речей.': 14, 'кожна': 15, 'сестра': 16, 'бене': 17, 'ґессерит': 18, 'знає': 19, 'це.': 20, 'тож,': 21, 'приступаючи': 22, 'до': 23, 'вивчення': 24, 'життя': 25, 'муад’діба,': 26, 'зважте': 27, 'спершу': 28, 'на': 29, 'те,': 30, 'у': 31, 'які': 32, 'часи': 33, 'він': 34, 'з’явився,': 35, 'бо': 36, 'ж': 37, 'народився': 38, 'владар': 39, 'рік': 40, 'п’ятдесят': 41, 'сьомий': 42, 'правління': 43, 'падишаха-імператора': 44, 'шаддама': 45, 'iv.': 46, 'й': 47, 'особливо': 48, 'уважно': 49}\n",
      "{0: 'книга', 1: 'перша', 2: 'дюна', 3: 'початок', 4: '—', 5: 'то', 6: 'мить,', 7: 'коли', 8: 'варто', 9: 'якнайкраще', 10: 'подбати', 11: 'про', 12: 'істинну', 13: 'рівновагу', 14: 'речей.', 15: 'кожна', 16: 'сестра', 17: 'бене', 18: 'ґессерит', 19: 'знає', 20: 'це.', 21: 'тож,', 22: 'приступаючи', 23: 'до', 24: 'вивчення', 25: 'життя', 26: 'муад’діба,', 27: 'зважте', 28: 'спершу', 29: 'на', 30: 'те,', 31: 'у', 32: 'які', 33: 'часи', 34: 'він', 35: 'з’явився,', 36: 'бо', 37: 'ж', 38: 'народився', 39: 'владар', 40: 'рік', 41: 'п’ятдесят', 42: 'сьомий', 43: 'правління', 44: 'падишаха-імператора', 45: 'шаддама', 46: 'iv.', 47: 'й', 48: 'особливо', 49: 'уважно'}\n"
     ]
    }
   ],
   "source": [
    "words = cleaned_text.split()\n",
    "word_counts = Counter(words)\n",
    "vocab = list(word_counts.keys())\n",
    "vocab_size = len(vocab)\n",
    "\n",
    "word_to_int = {word: i for i, word in enumerate(vocab)}\n",
    "int_to_word = {i: word for word, i in word_to_int.items()}\n",
    "SEQUENCE_LENGTH = 64\n",
    "samples = [words[i:i+SEQUENCE_LENGTH+1] for i in range(len(words)-SEQUENCE_LENGTH)]\n",
    "\n",
    "print(vocab[:50])\n",
    "print(dict(list(word_to_int.items())[:50]))\n",
    "print(dict(list(int_to_word.items())[:50]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2758ef0",
   "metadata": {
    "papermill": {
     "duration": 0.003353,
     "end_time": "2025-12-22T19:24:17.431824",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.428471",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9117c175",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.440025Z",
     "iopub.status.busy": "2025-12-22T19:24:17.439421Z",
     "iopub.status.idle": "2025-12-22T19:24:17.444200Z",
     "shell.execute_reply": "2025-12-22T19:24:17.443528Z"
    },
    "papermill": {
     "duration": 0.010544,
     "end_time": "2025-12-22T19:24:17.445643",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.435099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextDataset(Dataset):\n",
    "    def __init__(self, samples, word_to_int):\n",
    "        self.samples = samples\n",
    "        self.word_to_int = word_to_int\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        input_seq = torch.LongTensor([self.word_to_int[word] for word in sample[:-1]])\n",
    "        target_seq = torch.LongTensor([self.word_to_int[word] for word in sample[1:]])\n",
    "        return input_seq, target_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7975f879",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.453741Z",
     "iopub.status.busy": "2025-12-22T19:24:17.453147Z",
     "iopub.status.idle": "2025-12-22T19:24:17.494129Z",
     "shell.execute_reply": "2025-12-22T19:24:17.493336Z"
    },
    "papermill": {
     "duration": 0.046619,
     "end_time": "2025-12-22T19:24:17.495566",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.448947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18,\n",
      "        19, 11, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "        36, 37, 38, 39, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n",
      "        34, 53, 29, 54, 55, 56, 57, 58, 59, 60]), tensor([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19,\n",
      "        11, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36,\n",
      "        37, 38, 39, 31, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 34,\n",
      "        53, 29, 54, 55, 56, 57, 58, 59, 60, 61]))\n"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "dataset = TextDataset(samples, word_to_int)\n",
    "dataloader = DataLoader(\n",
    "    dataset, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    shuffle=True, \n",
    ")\n",
    "print(dataset[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39567388",
   "metadata": {
    "papermill": {
     "duration": 0.004093,
     "end_time": "2025-12-22T19:24:17.503068",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.498975",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Model (Decoder Only Text Generation Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ecb9cc41",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.511533Z",
     "iopub.status.busy": "2025-12-22T19:24:17.511004Z",
     "iopub.status.idle": "2025-12-22T19:24:17.515119Z",
     "shell.execute_reply": "2025-12-22T19:24:17.514468Z"
    },
    "papermill": {
     "duration": 0.010088,
     "end_time": "2025-12-22T19:24:17.516464",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.506376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    \"\"\"\"\n",
    "    Generate a square mask for the sequence. The masked positions are filled with float('-inf').\n",
    "    Unmasked positions are filled with float(0.0).\n",
    "    \"\"\"\n",
    "    mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19121894",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.524087Z",
     "iopub.status.busy": "2025-12-22T19:24:17.523776Z",
     "iopub.status.idle": "2025-12-22T19:24:17.529356Z",
     "shell.execute_reply": "2025-12-22T19:24:17.528676Z"
    },
    "papermill": {
     "duration": 0.011045,
     "end_time": "2025-12-22T19:24:17.530762",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.519717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, max_len, d_model, dropout=0.1):\n",
    "        \"\"\"\n",
    "        :param max_len: Input length sequence.\n",
    "        :param d_model: Embedding dimension.\n",
    "        :param dropout: Dropout value (default=0.1)\n",
    "        \"\"\"\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Inputs of forward function\n",
    "        :param x: the sequence fed to the positional encoder model (required).\n",
    "        Shape:\n",
    "            x: [sequence length, batch size, embed dim]\n",
    "            output: [sequence length, batch size, embed dim]\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:, :x.size(1)]\n",
    "        return self.dropout(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "60e25740",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.538479Z",
     "iopub.status.busy": "2025-12-22T19:24:17.538210Z",
     "iopub.status.idle": "2025-12-22T19:24:17.543623Z",
     "shell.execute_reply": "2025-12-22T19:24:17.542964Z"
    },
    "papermill": {
     "duration": 0.010787,
     "end_time": "2025-12-22T19:24:17.544956",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.534169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TextGen(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim, num_layers, num_heads):\n",
    "        super(TextGen, self).__init__()\n",
    "        self.pos_encoder = PositionalEncoding(max_len=SEQUENCE_LENGTH, d_model=embed_dim)\n",
    "        self.emb = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.decoder_layer = nn.TransformerDecoderLayer(\n",
    "            d_model=embed_dim, \n",
    "            nhead=num_heads, \n",
    "            batch_first=True\n",
    "        )\n",
    "        self.decoder = nn.TransformerDecoder(\n",
    "            decoder_layer=self.decoder_layer,\n",
    "            num_layers=num_layers,\n",
    "        )\n",
    "        self.linear = nn.Linear(embed_dim, vocab_size)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    # Positional encoding is required. Else the model does not learn.\n",
    "    def forward(self, x):\n",
    "        emb = self.emb(x)\n",
    "        \n",
    "        # Generate input sequence mask with shape (SEQUENCE_LENGTH, SEQUENCE_LENGTH)\n",
    "        input_mask = generate_square_subsequent_mask(x.size(1)).to(x.device)\n",
    "        \n",
    "        x = self.pos_encoder(emb)\n",
    "        x = self.decoder(x, memory=x, tgt_mask=input_mask, memory_mask=input_mask)\n",
    "        x = self.dropout(x)\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5879e31c",
   "metadata": {
    "papermill": {
     "duration": 0.003176,
     "end_time": "2025-12-22T19:24:17.551536",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.548360",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "01030e39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.560605Z",
     "iopub.status.busy": "2025-12-22T19:24:17.560080Z",
     "iopub.status.idle": "2025-12-22T19:24:17.565302Z",
     "shell.execute_reply": "2025-12-22T19:24:17.564540Z"
    },
    "papermill": {
     "duration": 0.012005,
     "end_time": "2025-12-22T19:24:17.566756",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.554751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, epochs, dataloader, criterion):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0\n",
    "        for input_seq, target_seq in dataloader:\n",
    "            input_seq, target_seq = input_seq.to(device), target_seq.to(device)\n",
    "            outputs = model(input_seq)\n",
    "            target_seq = target_seq.contiguous().view(-1)\n",
    "            outputs = outputs.view(-1, vocab_size)\n",
    "            \n",
    "            loss = criterion(outputs, target_seq.view(-1))\n",
    "    \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.detach().cpu().numpy()\n",
    "        epoch_loss = running_loss / len(dataloader)\n",
    "        print(f\"Epoch {epoch} loss: {epoch_loss:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ce430a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:17.574615Z",
     "iopub.status.busy": "2025-12-22T19:24:17.574054Z",
     "iopub.status.idle": "2025-12-22T19:24:22.467513Z",
     "shell.execute_reply": "2025-12-22T19:24:22.466428Z"
    },
    "papermill": {
     "duration": 4.899124,
     "end_time": "2025-12-22T19:24:22.469162",
     "exception": false,
     "start_time": "2025-12-22T19:24:17.570038",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextGen(\n",
      "  (pos_encoder): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (emb): Embedding(51186, 100)\n",
      "  (decoder_layer): TransformerDecoderLayer(\n",
      "    (self_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (multihead_attn): MultiheadAttention(\n",
      "      (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "    )\n",
      "    (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "    (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "    (dropout1): Dropout(p=0.1, inplace=False)\n",
      "    (dropout2): Dropout(p=0.1, inplace=False)\n",
      "    (dropout3): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (decoder): TransformerDecoder(\n",
      "    (layers): ModuleList(\n",
      "      (0-1): 2 x TransformerDecoderLayer(\n",
      "        (self_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "        )\n",
      "        (multihead_attn): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=100, out_features=100, bias=True)\n",
      "        )\n",
      "        (linear1): Linear(in_features=100, out_features=2048, bias=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (linear2): Linear(in_features=2048, out_features=100, bias=True)\n",
      "        (norm1): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm2): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (norm3): LayerNorm((100,), eps=1e-05, elementwise_affine=True)\n",
      "        (dropout1): Dropout(p=0.1, inplace=False)\n",
      "        (dropout2): Dropout(p=0.1, inplace=False)\n",
      "        (dropout3): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (linear): Linear(in_features=100, out_features=51186, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      ")\n",
      "11,767,830 total parameters.\n",
      "11,767,830 training parameters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "learning_rate = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TextGen(\n",
    "    vocab_size=vocab_size, \n",
    "    embed_dim=100,\n",
    "    num_layers=2, \n",
    "    num_heads=2,\n",
    ").to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "print(model)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"{total_params:,} total parameters.\")\n",
    "\n",
    "total_trainable_params = sum(\n",
    "    p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"{total_trainable_params:,} training parameters.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a03ea485",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-22T19:24:22.478298Z",
     "iopub.status.busy": "2025-12-22T19:24:22.477654Z",
     "iopub.status.idle": "2025-12-23T06:14:36.912652Z",
     "shell.execute_reply": "2025-12-23T06:14:36.911872Z"
    },
    "papermill": {
     "duration": 39014.448255,
     "end_time": "2025-12-23T06:14:36.921148",
     "exception": false,
     "start_time": "2025-12-22T19:24:22.472893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 loss: 4.550\n",
      "Epoch 1 loss: 2.665\n",
      "Epoch 2 loss: 2.052\n",
      "Epoch 3 loss: 1.631\n",
      "Epoch 4 loss: 1.321\n",
      "Epoch 5 loss: 1.094\n",
      "Epoch 6 loss: 0.929\n",
      "Epoch 7 loss: 0.808\n",
      "Epoch 8 loss: 0.718\n",
      "Epoch 9 loss: 0.651\n",
      "Epoch 10 loss: 0.598\n",
      "Epoch 11 loss: 0.556\n",
      "Epoch 12 loss: 0.522\n",
      "Epoch 13 loss: 0.494\n",
      "Epoch 14 loss: 0.471\n",
      "Epoch 15 loss: 0.450\n",
      "Epoch 16 loss: 0.433\n",
      "Epoch 17 loss: 0.418\n",
      "Epoch 18 loss: 0.405\n",
      "Epoch 19 loss: 0.393\n",
      "Epoch 20 loss: 0.383\n",
      "Epoch 21 loss: 0.374\n",
      "Epoch 22 loss: 0.365\n",
      "Epoch 23 loss: 0.357\n",
      "Epoch 24 loss: 0.351\n",
      "Epoch 25 loss: 0.345\n",
      "Epoch 26 loss: 0.339\n",
      "Epoch 27 loss: 0.333\n",
      "Epoch 28 loss: 0.329\n",
      "Epoch 29 loss: 0.324\n",
      "Epoch 30 loss: 0.320\n",
      "Epoch 31 loss: 0.316\n",
      "Epoch 32 loss: 0.313\n",
      "Epoch 33 loss: 0.309\n",
      "Epoch 34 loss: 0.306\n",
      "Epoch 35 loss: 0.303\n",
      "Epoch 36 loss: 0.300\n",
      "Epoch 37 loss: 0.297\n",
      "Epoch 38 loss: 0.295\n",
      "Epoch 39 loss: 0.292\n",
      "Epoch 40 loss: 0.290\n",
      "Epoch 41 loss: 0.288\n",
      "Epoch 42 loss: 0.286\n",
      "Epoch 43 loss: 0.284\n",
      "Epoch 44 loss: 0.282\n",
      "Epoch 45 loss: 0.280\n",
      "Epoch 46 loss: 0.279\n",
      "Epoch 47 loss: 0.277\n",
      "Epoch 48 loss: 0.275\n",
      "Epoch 49 loss: 0.274\n",
      "Epoch 50 loss: 0.272\n",
      "Epoch 51 loss: 0.271\n",
      "Epoch 52 loss: 0.270\n",
      "Epoch 53 loss: 0.268\n",
      "Epoch 54 loss: 0.267\n",
      "Epoch 55 loss: 0.266\n",
      "Epoch 56 loss: 0.265\n",
      "Epoch 57 loss: 0.264\n",
      "Epoch 58 loss: 0.263\n",
      "Epoch 59 loss: 0.262\n",
      "Epoch 60 loss: 0.261\n",
      "Epoch 61 loss: 0.260\n",
      "Epoch 62 loss: 0.259\n",
      "Epoch 63 loss: 0.258\n",
      "Epoch 64 loss: 0.257\n",
      "Epoch 65 loss: 0.257\n",
      "Epoch 66 loss: 0.256\n",
      "Epoch 67 loss: 0.255\n",
      "Epoch 68 loss: 0.254\n",
      "Epoch 69 loss: 0.253\n",
      "Epoch 70 loss: 0.253\n",
      "Epoch 71 loss: 0.252\n",
      "Epoch 72 loss: 0.251\n",
      "Epoch 73 loss: 0.251\n",
      "Epoch 74 loss: 0.250\n",
      "Epoch 75 loss: 0.249\n",
      "Epoch 76 loss: 0.249\n",
      "Epoch 77 loss: 0.248\n",
      "Epoch 78 loss: 0.248\n",
      "Epoch 79 loss: 0.247\n",
      "Epoch 80 loss: 0.247\n",
      "Epoch 81 loss: 0.246\n",
      "Epoch 82 loss: 0.245\n",
      "Epoch 83 loss: 0.245\n",
      "Epoch 84 loss: 0.244\n",
      "Epoch 85 loss: 0.244\n",
      "Epoch 86 loss: 0.243\n",
      "Epoch 87 loss: 0.243\n",
      "Epoch 88 loss: 0.243\n",
      "Epoch 89 loss: 0.242\n",
      "Epoch 90 loss: 0.241\n",
      "Epoch 91 loss: 0.241\n",
      "Epoch 92 loss: 0.241\n",
      "Epoch 93 loss: 0.240\n",
      "Epoch 94 loss: 0.240\n",
      "Epoch 95 loss: 0.239\n",
      "Epoch 96 loss: 0.239\n",
      "Epoch 97 loss: 0.239\n",
      "Epoch 98 loss: 0.238\n",
      "Epoch 99 loss: 0.238\n"
     ]
    }
   ],
   "source": [
    "train(model, epochs, dataloader, criterion) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb12022",
   "metadata": {
    "papermill": {
     "duration": 0.006919,
     "end_time": "2025-12-23T06:14:36.934793",
     "exception": false,
     "start_time": "2025-12-23T06:14:36.927874",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1af22e00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:14:36.949914Z",
     "iopub.status.busy": "2025-12-23T06:14:36.949337Z",
     "iopub.status.idle": "2025-12-23T06:14:36.955673Z",
     "shell.execute_reply": "2025-12-23T06:14:36.955056Z"
    },
    "papermill": {
     "duration": 0.015553,
     "end_time": "2025-12-23T06:14:36.956984",
     "exception": false,
     "start_time": "2025-12-23T06:14:36.941431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def return_int_vector(text):\n",
    "    words = text.split()\n",
    "    input_seq = torch.LongTensor([word_to_int[word] for word in words[-SEQUENCE_LENGTH:]]).unsqueeze(0)\n",
    "    return input_seq\n",
    "    \n",
    "def sample_next(predictions):\n",
    "    \"\"\"\n",
    "    Greedy sampling.\n",
    "    \"\"\"\n",
    "    # Greedy approach.\n",
    "    probabilities = F.softmax(predictions[:, -1, :], dim=-1).cpu()\n",
    "    next_token = torch.argmax(probabilities)\n",
    "    return int(next_token.cpu())\n",
    "    \n",
    "def text_generator(sentence, generate_length):\n",
    "    model.eval()\n",
    "    sample = sentence\n",
    "    for i in range(generate_length):\n",
    "        int_vector = return_int_vector(sample)\n",
    "        if len(int_vector) >= SEQUENCE_LENGTH - 1:\n",
    "            break\n",
    "        input_tensor = int_vector.to(device)\n",
    "        with torch.no_grad():\n",
    "            predictions = model(input_tensor)\n",
    "        next_token = sample_next(predictions)\n",
    "        sample += ' ' + int_to_word[next_token]\n",
    "    print(sample)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7da6de2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-23T06:14:36.971836Z",
     "iopub.status.busy": "2025-12-23T06:14:36.971627Z",
     "iopub.status.idle": "2025-12-23T06:14:37.390196Z",
     "shell.execute_reply": "2025-12-23T06:14:37.389276Z"
    },
    "papermill": {
     "duration": 0.428136,
     "end_time": "2025-12-23T06:14:37.391985",
     "exception": false,
     "start_time": "2025-12-23T06:14:36.963849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROMPT: імператор пол був\n",
      "імператор пол був безумцем, дункане! — не кажи так! — різко відповів він. — увесь всесвіт скаже це, перш ніж я договорю. — чого б це, заради любові до небес? — заради любові до мого брата, не до небес. дзен-сунітська проникливість розширила його свідомість. він бачив, що алія не мала видінь — жодного, відколи померла чані. — дивна твоя любов, — сказав він. — любов! дункане, йому достатньо було вийти з колії! яке значення мала решта всесвіту, що завалилася б позаду нього? він був би в безпеці… і чані з ним! — то… чому ж не зробив так? — заради любові до небес,\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"імператор пол був\"\n",
    "]\n",
    "\n",
    "generate_length = 100\n",
    "for sentence in sentences:\n",
    "    print(f\"PROMPT: {sentence}\")\n",
    "    text_generator(sentence, generate_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8425dcba",
   "metadata": {
    "papermill": {
     "duration": 0.00747,
     "end_time": "2025-12-23T06:14:37.407709",
     "exception": false,
     "start_time": "2025-12-23T06:14:37.400239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5889335,
     "sourceId": 9643798,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31236,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 39037.819923,
   "end_time": "2025-12-23T06:14:39.639070",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-12-22T19:24:01.819147",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
